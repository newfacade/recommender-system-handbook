{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema\n",
    "\n",
    "```{note}\n",
    "对于大型数据集，我们一般不自动推测字段类型，而是使用schema定义数据的结构。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark数据类型\n",
    "\n",
    "要定义schema，首先需要了解Spark支持的数据类型。\n",
    "\n",
    "基础数据类型：\n",
    "\n",
    "![jupyter](../images/type1.jpg)\n",
    "\n",
    "复杂数据类型：\n",
    "\n",
    "![jupyter](../images/type2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our static data\n",
    "data = [[\"Xia\", \"Deep Play\", 99],\n",
    "        [\"Ronaldo\", \"Basic Football\", 9999],\n",
    "        [\"Wang\", \"How to Earn 100M\", 73281]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# 第一种定义方式\n",
    "# author、title、pages三个字段，类型分别为str、str、int\n",
    "# `False` Indicates this field can't be null values.\n",
    "schema = StructType([StructField(\"author\", StringType(), False),\n",
    "                     StructField(\"title\", StringType(), False),\n",
    "                     StructField(\"pages\", IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二种定义方式，就像数据库\n",
    "schema = \"author STRING, title STRING, pages INT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用schema指定DataFrame的数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+-----+\n",
      "| author|           title|pages|\n",
      "+-------+----------------+-----+\n",
      "|    Xia|       Deep Play|   99|\n",
      "|Ronaldo|  Basic Football| 9999|\n",
      "|   Wang|How to Earn 100M|73281|\n",
      "+-------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"schema_example\")\n",
    "         .getOrCreate())\n",
    "# Create a DataFrame using the schema defined above\n",
    "df = spark.createDataFrame(data, schema)\n",
    "# Show the DataFrame; it should reflect our table above\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- pages: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 打印schema\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
